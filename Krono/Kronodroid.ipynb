{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2be1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "#from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import autokeras as ak\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64654307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93d440",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def2d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "krono_data_path1 = 'data/kronodroid.csv'\n",
    "# Importing the dataset\n",
    "Krono_data = pd.read_csv(krono_data_path1)\n",
    "Krono_data = Krono_data.sample(frac = 1)\n",
    "X = Krono_data.iloc[:,range(1,Krono_data.shape[1]-1)].values\n",
    "y = Krono_data.iloc[:, -1].values\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.astype(int), test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1699ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "RFC\n",
      "accuracy 0.9583653271905127\n",
      "---------------------------\n",
      "SVM\n",
      "accuracy 0.909180104086682\n",
      "---------------------------\n",
      "SGD\n",
      "accuracy 0.9371640644996161\n",
      "---------------------------\n",
      "XGB\n",
      "accuracy 0.9484685607030117\n",
      "---------------------------\n",
      "LGBM\n",
      "accuracy 0.9561044279498336\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# \"GaussianNB\": GaussianNB(), \"DT\": DecisionTreeClassifier(), \"MLP\": MLPClassifier(random_state=1, max_iter=300),\n",
    "# 47.9%, 65.8%, 79%,  \n",
    "classifiers = {\"RFC\": RandomForestClassifier(), \"SVM\": SVC(kernel = 'poly', degree=3), \"SGD\": SGDClassifier(), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "\n",
    "for classifier_pair in classifiers.items():\n",
    "    print(\"---------------------------\")\n",
    "    print(classifier_pair[0])\n",
    "    \n",
    "    classifier = classifier_pair[1]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix', cm)\n",
    "\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "\n",
    "    #compute precision score\n",
    "    precision_score = precision(y_test, y_pred, average='micro')\n",
    "    print('precision', precision_score)\n",
    "\n",
    "    #compute recall score\n",
    "    recall_score = recall(y_test, y_pred)\n",
    "    print('recall', recall_score)\n",
    "\n",
    "    #compute f1 score\n",
    "    f1_score = f1(y_test, y_pred)\n",
    "    print('f1', f1_score)\n",
    "    \n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f757783",
   "metadata": {},
   "source": [
    "# Ensemble Learning - Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d49449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(y_preds, y_test):\n",
    "    assert y_preds.shape[0] == len(y_test), \"y_preds's length is: {} while y_test's length is: {}. They should be equal.\".format(y_preds.shape[0],len(y_test))\n",
    "    y_pred_vote = []\n",
    "    for preds in y_preds:\n",
    "        if sum(preds) >= 3:\n",
    "            y_pred_vote.append(1)\n",
    "        else:\n",
    "            y_pred_vote.append(0)\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred_vote)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6163769b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;28mlen\u001b[39m(y_test)))\n\u001b[0;32m      2\u001b[0m i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classifier_pair \u001b[38;5;129;01min\u001b[39;00m \u001b[43mclassifiers\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      4\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m classifier_pair[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m     y_preds[i] \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "y_preds = np.ndarray(shape=(5,len(y_test)))\n",
    "i=0\n",
    "for classifier_pair in classifiers.items():\n",
    "    classifier = classifier_pair[1]\n",
    "    y_preds[i] = classifier.predict(X_test)\n",
    "    i += 1\n",
    "y_preds = np.transpose(y_preds)\n",
    "print('accuracy', majority_voting(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8bd8e2",
   "metadata": {},
   "source": [
    "# Label Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a21ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_label_flipping(X_train, X_test, y_train, y_test, per, classifier):\n",
    "    flipped_data = specific_label_flipping(y_train, per, 1)\n",
    "    classifier.fit(X_train, flipped_data)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    return y_pred, acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8929ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flipping Random\n",
    "def random_label_flipping(y_train, per):\n",
    "    flip_count = int(per*(len(y_train)))\n",
    "    flipped_data = copy.deepcopy(y_train)\n",
    "    indices = random.sample(range(len(flipped_data)), flip_count)\n",
    "    for j in indices:\n",
    "        flipped_data[j] = (flipped_data[j] + 1)%2\n",
    "    return flipped_data\n",
    "\n",
    "#Flipping Specific\n",
    "def specific_label_flipping(y_train, per, target):\n",
    "    flipped_data = copy.deepcopy(y_train)\n",
    "    possible_indices = []\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] == target:\n",
    "            possible_indices.append(i)\n",
    "    flip_count = int(per*(len(possible_indices)))\n",
    "    indices = random.sample(possible_indices, flip_count)\n",
    "    for j in indices:\n",
    "        flipped_data[j] = (flipped_data[j] + 1)%2\n",
    "    return flipped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26f8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Trial #1 is starting...\n",
      "Trial #1 is completed with accuracy: 0.9430935926968689\n",
      "---------------------------\n",
      "Trial #2 is starting...\n",
      "Trial #2 is completed with accuracy: 0.9404061086937975\n",
      "---------------------------\n",
      "Trial #3 is starting...\n",
      "Trial #3 is completed with accuracy: 0.9473167818445525\n",
      "---------------------------\n",
      "Trial #4 is starting...\n",
      "Trial #4 is completed with accuracy: 0.9472314648920741\n",
      "---------------------------\n",
      "Trial #5 is starting...\n",
      "Trial #5 is completed with accuracy: 0.9446719563177204\n",
      "---------------------------\n",
      "Random Poisoning - 0.2\n",
      "RFC's average accuracy: 0.9245286238375566\n",
      "SVM's average accuracy: 0.8422660182578279\n",
      "SGD's average accuracy: 0.8896339902738675\n",
      "XGB's average accuracy: 0.9248869550379659\n",
      "LGBM's average accuracy: 0.9502687484003071\n",
      "Average ensemble accuracy: 0.9445439808890027\n"
     ]
    }
   ],
   "source": [
    "percentages = [0.01, 0.05, 0.1, 0.2]\n",
    "per = percentages[3]\n",
    "poisoned_accuracies = {\"RFC\": [], \"SVM\": [], \"SGD\": [], \"XGB\": [], \"LGBM\": []} \n",
    "ensemble_accuracies = []\n",
    "\n",
    "print(\"---------------------------\")\n",
    "for i in range(5):\n",
    "    print(\"Trial #{} is starting...\".format(i+1))\n",
    "    \n",
    "    poisoned_classifiers = {\"RFC\": RandomForestClassifier(), \"SVM\": SVC(kernel = 'poly', degree=3), \"SGD\": SGDClassifier(), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "       \n",
    "    y_preds = np.ndarray(shape=(len(poisoned_classifiers),len(y_test)))\n",
    "    j=0\n",
    "    for classifier_pair in poisoned_classifiers.items():\n",
    "        poisoned_y_pred, poisoned_accuracy = attack_label_flipping(X_train, X_test, y_train, y_test, per, classifier_pair[1])\n",
    "        y_preds[j] = poisoned_y_pred\n",
    "        j+=1\n",
    "        poisoned_accuracies[classifier_pair[0]].append(poisoned_accuracy)    \n",
    "    y_preds = np.transpose(y_preds)\n",
    "    \n",
    "    ensemble_accuracy = majority_voting(y_preds, y_test)\n",
    "    ensemble_accuracies.append(ensemble_accuracy)\n",
    "    \n",
    "    print(\"Trial #{} is completed with accuracy: {}\".format(i+1, ensemble_accuracy))\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "print(\"Random Poisoning - {}\".format(per))\n",
    "for classifier_pair in poisoned_accuracies.items():\n",
    "    accuracies = classifier_pair[1]\n",
    "    print(\"{}'s average accuracy: {}\".format(classifier_pair[0], sum(accuracies)/len(accuracies)))\n",
    "print(\"Average ensemble accuracy:\", sum(ensemble_accuracies)/len(ensemble_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7882a32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 08m 28s]\n",
      "val_accuracy: 0.8348749876022339\n",
      "\n",
      "Best val_accuracy So Far: 0.9527429342269897\n",
      "Total elapsed time: 02h 36m 28s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "1710/1710 [==============================] - 22s 10ms/step - loss: 0.1635 - accuracy: 0.9409\n",
      "INFO:tensorflow:Assets written to: .\\structured_data_classifier\\best_model\\assets\n",
      "733/733 [==============================] - 11s 11ms/step - loss: 321648.8750 - accuracy: 0.5288\n",
      "[321648.875, 0.528751790523529]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the structured data classifier.\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True, max_trials=15\n",
    ")  # It tries different models.\n",
    "# Feed the structured data classifier with training data.\n",
    "clf.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=1,\n",
    ")\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x=X_test, y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddc14400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 462)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 462)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 462)              925       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                14816     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               16896     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " classification_head_1 (Acti  (None, 1)                0         \n",
      " vation)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,150\n",
      "Trainable params: 32,225\n",
      "Non-trainable params: 925\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "425e16c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733/733 [==============================] - 9s 12ms/step - loss: 321648.8750 - accuracy: 0.5288\n",
      "test loss, test acc: [321648.875, 0.528751790523529]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac750e0e",
   "metadata": {},
   "source": [
    "## Poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0836fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.ml.classifiers.sklearn.c_classifier_logistic import CClassifierLogistic\n",
    "from secml.adv.attacks.poisoning.c_attack_poisoning_logistic_regression import CAttackPoisoningLogisticRegression\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "\n",
    "lb, ub = 0., 1.  # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "n_poisoning_points = 15  # Number of poisoning points to generate\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.25,\n",
    "    'eta_min': 2.0,\n",
    "    'eta_max': None,\n",
    "    'max_iter': 100,\n",
    "    'eps': 1e-6\n",
    "}\n",
    "\n",
    "dataset = CDataset(X_train, y_train)\n",
    "metric = CMetricAccuracy()\n",
    "\n",
    "# train SVM in the dual space, on a linear kernel, as needed for poisoning\n",
    "c_classifier_LR = CClassifierLogistic()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a757cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of c_classifier_SVM...\n",
      "CArray([1 1 0 ... 1 1 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/atahantap/Research Project/Label-Differential-Privacy/Krono/Kronodroid.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/atahantap/Research%20Project/Label-Differential-Privacy/Krono/Kronodroid.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m c_classifier_LR\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/atahantap/Research%20Project/Label-Differential-Privacy/Krono/Kronodroid.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(y_pred)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/atahantap/Research%20Project/Label-Differential-Privacy/Krono/Kronodroid.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pois_attack \u001b[39m=\u001b[39m CAttackPoisoningLogisticRegression(classifier\u001b[39m=\u001b[39;49mc_classifier_LR,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/atahantap/Research%20Project/Label-Differential-Privacy/Krono/Kronodroid.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                 training_data\u001b[39m=\u001b[39;49mdataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/atahantap/Research%20Project/Label-Differential-Privacy/Krono/Kronodroid.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                 val\u001b[39m=\u001b[39;49mdataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/atahantap/Research%20Project/Label-Differential-Privacy/Krono/Kronodroid.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m pois_attack\u001b[39m.\u001b[39mn_points \u001b[39m=\u001b[39m n_poisoning_points\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/atahantap/Research%20Project/Label-Differential-Privacy/Krono/Kronodroid.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Run the poisoning attack\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/secml/adv/attacks/poisoning/c_attack_poisoning_logistic_regression.py:81\u001b[0m, in \u001b[0;36mCAttackPoisoningLogisticRegression.__init__\u001b[0;34m(self, classifier, training_data, val, distance, dmax, lb, ub, y_target, solver_type, solver_params, init_type, random_seed)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, classifier,\n\u001b[1;32m     69\u001b[0m              training_data,\n\u001b[1;32m     70\u001b[0m              val,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m              init_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     79\u001b[0m              random_seed\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 81\u001b[0m     CAttackPoisoning\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, classifier\u001b[39m=\u001b[39;49mclassifier,\n\u001b[1;32m     82\u001b[0m                               training_data\u001b[39m=\u001b[39;49mtraining_data,\n\u001b[1;32m     83\u001b[0m                               val\u001b[39m=\u001b[39;49mval,\n\u001b[1;32m     84\u001b[0m                               distance\u001b[39m=\u001b[39;49mdistance,\n\u001b[1;32m     85\u001b[0m                               dmax\u001b[39m=\u001b[39;49mdmax,\n\u001b[1;32m     86\u001b[0m                               lb\u001b[39m=\u001b[39;49mlb,\n\u001b[1;32m     87\u001b[0m                               ub\u001b[39m=\u001b[39;49mub,\n\u001b[1;32m     88\u001b[0m                               y_target\u001b[39m=\u001b[39;49my_target,\n\u001b[1;32m     89\u001b[0m                               solver_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[1;32m     90\u001b[0m                               solver_params\u001b[39m=\u001b[39;49msolver_params,\n\u001b[1;32m     91\u001b[0m                               init_type\u001b[39m=\u001b[39;49minit_type,\n\u001b[1;32m     92\u001b[0m                               random_seed\u001b[39m=\u001b[39;49mrandom_seed)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/secml/adv/attacks/poisoning/c_attack_poisoning.py:116\u001b[0m, in \u001b[0;36mCAttackPoisoning.__init__\u001b[0;34m(self, classifier, training_data, val, distance, dmax, lb, ub, y_target, solver_type, solver_params, init_type, random_seed)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_seed \u001b[39m=\u001b[39m random_seed\n\u001b[1;32m    114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_type \u001b[39m=\u001b[39m init_type\n\u001b[0;32m--> 116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meta \u001b[39m=\u001b[39m solver_params[\u001b[39m'\u001b[39;49m\u001b[39meta\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m    118\u001b[0m \u001b[39m# this is used to speed up some poisoning algorithms by re-using\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m# the solution obtained at a previous step of the optimization\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warm_start \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(\"Training of c_classifier_LR...\")\n",
    "c_classifier_LR.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = c_classifier_LR.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "pois_attack = CAttackPoisoningLogisticRegression(classifier=c_classifier_LR,\n",
    "                                training_data=dataset,\n",
    "                                val=dataset)\n",
    "pois_attack.n_points = n_poisoning_points\n",
    "\n",
    "# Run the poisoning attack\n",
    "print(\"Attack started...\")\n",
    "pois_y_pred, _, pois_points_ds, _ = pois_attack.run(X_test, y_test)\n",
    "print(\"Attack complete!\")\n",
    "\n",
    "# Evaluate the accuracy of the original classifier\n",
    "acc = metric.performance_score(y_true=y_test, y_pred=c_classifier_LR.predict(X_test))\n",
    "# Evaluate the accuracy after the poisoning attack\n",
    "pois_acc = metric.performance_score(y_true=y_test, y_pred=pois_y_pred)\n",
    "\n",
    "print(\"Original accuracy on test set: {:.2%}\".format(acc))\n",
    "print(\"Accuracy after attack on test set: {:.2%}\".format(pois_acc))\n",
    "\n",
    "print(\"\\n\\n---------------------------\")\n",
    "print(\"END OF LR POISONING\")\n",
    "print(\"---------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312d1c5",
   "metadata": {},
   "source": [
    "## Training with Poisoned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from secml.ml.classifiers.sklearn.c_classifier_sklearn import CClassifierSkLearn\n",
    "from secml.adv.attacks import CAttackPoisoningSVM\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "\n",
    "lb, ub = 0., 1.  # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "n_poisoning_points = 15  # Number of poisoning points to generate\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.25,\n",
    "    'eta_min': 2.0,\n",
    "    'eta_max': None,\n",
    "    'max_iter': 100,\n",
    "    'eps': 1e-6\n",
    "}\n",
    "\n",
    "classifiers = {\"RFC\": RandomForestClassifier(), \"SVM\": SVC(kernel = 'poly', degree=3), \"SGD\": SGDClassifier(), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "\n",
    "dataset = CDataset(X_train, y_train)\n",
    "\n",
    "metric = CMetricAccuracy()\n",
    "\n",
    "for classifier_pair in classifiers.items():\n",
    "    print(\"---------------------------\")\n",
    "    print(classifier_pair[0])\n",
    "    \n",
    "    classifier = classifier_pair[1]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix', cm)\n",
    "\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "\n",
    "    #compute precision score\n",
    "    precision_score = precision(y_test, y_pred, average='micro')\n",
    "    print('precision', precision_score)\n",
    "\n",
    "    #compute recall score\n",
    "    recall_score = recall(y_test, y_pred)\n",
    "    print('recall', recall_score)\n",
    "\n",
    "    #compute f1 score\n",
    "    f1_score = f1(y_test, y_pred)\n",
    "    print('f1', f1_score)\n",
    "\n",
    "    print(\"---------------------------\")\n",
    "    print(\"POISONING\")\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "    classifier = CClassifierSkLearn(classifier)\n",
    "\n",
    "    pois_attack = CAttackPoisoningSVM(classifier=classifier,\n",
    "                                  training_data=dataset,\n",
    "                                  val=dataset,\n",
    "                                  lb=lb, ub=ub,\n",
    "                                  solver_params=solver_params)\n",
    "    pois_attack.n_points = n_poisoning_points\n",
    "\n",
    "    # Run the poisoning attack\n",
    "    print(\"Attack started...\")\n",
    "    pois_y_pred, _, pois_points_ds, _ = pois_attack.run(X_test, y_test)\n",
    "    print(\"Attack complete!\")\n",
    "\n",
    "    # Evaluate the accuracy of the original classifier\n",
    "    acc = metric.performance_score(y_true=y_test, y_pred=classifier.predict(X_test))\n",
    "    # Evaluate the accuracy after the poisoning attack\n",
    "    pois_acc = metric.performance_score(y_true=y_test, y_pred=pois_y_pred)\n",
    "\n",
    "    print(\"Original accuracy on test set: {:.2%}\".format(acc))\n",
    "    print(\"Accuracy after attack on test set: {:.2%}\".format(pois_acc))\n",
    "\n",
    "    print(\"\\n\\n---------------------------\")\n",
    "    print(\"END OF MODEL\")\n",
    "    print(\"\\n\\n---------------------------\")\n",
    "\n",
    "\n",
    "print(\"---------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
