{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2be1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "#from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import autokeras as ak\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64654307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93d440",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def2d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "krono_data_path1 = 'data/kronodroid.csv'\n",
    "# Importing the dataset\n",
    "Krono_data = pd.read_csv(krono_data_path1)\n",
    "Krono_data = Krono_data.sample(frac = 1)\n",
    "X = Krono_data.iloc[:,range(1,Krono_data.shape[1]-1)].values\n",
    "y = Krono_data.iloc[:, -1].values\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.astype(int), test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1699ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "RFC\n",
      "accuracy 0.9583653271905127\n",
      "---------------------------\n",
      "SVM\n",
      "accuracy 0.909180104086682\n",
      "---------------------------\n",
      "SGD\n",
      "accuracy 0.9371640644996161\n",
      "---------------------------\n",
      "XGB\n",
      "accuracy 0.9484685607030117\n",
      "---------------------------\n",
      "LGBM\n",
      "accuracy 0.9561044279498336\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# \"GaussianNB\": GaussianNB(), \"DT\": DecisionTreeClassifier(), \"MLP\": MLPClassifier(random_state=1, max_iter=300),\n",
    "# 47.9%, 65.8%, 79%,  \n",
    "classifiers = {\"RFC\": RandomForestClassifier(), \"SVM\": SVC(kernel = 'poly', degree=3), \"SGD\": SGDClassifier(), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "\n",
    "for classifier_pair in classifiers.items():\n",
    "    print(\"---------------------------\")\n",
    "    print(classifier_pair[0])\n",
    "    \n",
    "    classifier = classifier_pair[1]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix', cm)\n",
    "\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "\n",
    "    #compute precision score\n",
    "    precision_score = precision(y_test, y_pred, average='micro')\n",
    "    print('precision', precision_score)\n",
    "\n",
    "    #compute recall score\n",
    "    recall_score = recall(y_test, y_pred)\n",
    "    print('recall', recall_score)\n",
    "\n",
    "    #compute f1 score\n",
    "    f1_score = f1(y_test, y_pred)\n",
    "    print('f1', f1_score)\n",
    "    \n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f757783",
   "metadata": {},
   "source": [
    "# Ensemble Learning - Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d49449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(y_preds, y_test):\n",
    "    assert y_preds.shape[0] == len(y_test), \"y_preds's length is: {} while y_test's length is: {}. They should be equal.\".format(y_preds.shape[0],len(y_test))\n",
    "    y_pred_vote = []\n",
    "    for preds in y_preds:\n",
    "        if sum(preds) >= 3:\n",
    "            y_pred_vote.append(1)\n",
    "        else:\n",
    "            y_pred_vote.append(0)\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred_vote)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.ndarray(shape=(5,len(y_test)))\n",
    "i=0\n",
    "for classifier_pair in classifiers.items():\n",
    "    classifier = classifier_pair[1]\n",
    "    y_preds[i] = classifier.predict(X_test)\n",
    "    i += 1\n",
    "y_preds = np.transpose(y_preds)\n",
    "print('accuracy', majority_voting(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8bd8e2",
   "metadata": {},
   "source": [
    "# Label Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a21ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_label_flipping(X_train, X_test, y_train, y_test, per, classifier):\n",
    "    flipped_data = specific_label_flipping(y_train, per, 1)\n",
    "    classifier.fit(X_train, flipped_data)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    return y_pred, acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8929ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flipping Random\n",
    "def random_label_flipping(y_train, per):\n",
    "    flip_count = int(per*(len(y_train)))\n",
    "    flipped_data = copy.deepcopy(y_train)\n",
    "    indices = random.sample(range(len(flipped_data)), flip_count)\n",
    "    for j in indices:\n",
    "        flipped_data[j] = (flipped_data[j] + 1)%2\n",
    "    return flipped_data\n",
    "\n",
    "#Flipping Specific\n",
    "def specific_label_flipping(y_train, per, target):\n",
    "    flipped_data = copy.deepcopy(y_train)\n",
    "    possible_indices = []\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] == target:\n",
    "            possible_indices.append(i)\n",
    "    flip_count = int(per*(len(possible_indices)))\n",
    "    indices = random.sample(possible_indices, flip_count)\n",
    "    for j in indices:\n",
    "        flipped_data[j] = (flipped_data[j] + 1)%2\n",
    "    return flipped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26f8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Trial #1 is starting...\n",
      "Trial #1 is completed with accuracy: 0.9430935926968689\n",
      "---------------------------\n",
      "Trial #2 is starting...\n",
      "Trial #2 is completed with accuracy: 0.9404061086937975\n",
      "---------------------------\n",
      "Trial #3 is starting...\n",
      "Trial #3 is completed with accuracy: 0.9473167818445525\n",
      "---------------------------\n",
      "Trial #4 is starting...\n",
      "Trial #4 is completed with accuracy: 0.9472314648920741\n",
      "---------------------------\n",
      "Trial #5 is starting...\n",
      "Trial #5 is completed with accuracy: 0.9446719563177204\n",
      "---------------------------\n",
      "Random Poisoning - 0.2\n",
      "RFC's average accuracy: 0.9245286238375566\n",
      "SVM's average accuracy: 0.8422660182578279\n",
      "SGD's average accuracy: 0.8896339902738675\n",
      "XGB's average accuracy: 0.9248869550379659\n",
      "LGBM's average accuracy: 0.9502687484003071\n",
      "Average ensemble accuracy: 0.9445439808890027\n"
     ]
    }
   ],
   "source": [
    "percentages = [0.01, 0.05, 0.1, 0.2]\n",
    "per = percentages[3]\n",
    "poisoned_accuracies = {\"RFC\": [], \"SVM\": [], \"SGD\": [], \"XGB\": [], \"LGBM\": []} \n",
    "ensemble_accuracies = []\n",
    "\n",
    "print(\"---------------------------\")\n",
    "for i in range(5):\n",
    "    print(\"Trial #{} is starting...\".format(i+1))\n",
    "    \n",
    "    poisoned_classifiers = {\"RFC\": RandomForestClassifier(), \"SVM\": SVC(kernel = 'poly', degree=3), \"SGD\": SGDClassifier(), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "       \n",
    "    y_preds = np.ndarray(shape=(len(poisoned_classifiers),len(y_test)))\n",
    "    j=0\n",
    "    for classifier_pair in poisoned_classifiers.items():\n",
    "        poisoned_y_pred, poisoned_accuracy = attack_label_flipping(X_train, X_test, y_train, y_test, per, classifier_pair[1])\n",
    "        y_preds[j] = poisoned_y_pred\n",
    "        j+=1\n",
    "        poisoned_accuracies[classifier_pair[0]].append(poisoned_accuracy)    \n",
    "    y_preds = np.transpose(y_preds)\n",
    "    \n",
    "    ensemble_accuracy = majority_voting(y_preds, y_test)\n",
    "    ensemble_accuracies.append(ensemble_accuracy)\n",
    "    \n",
    "    print(\"Trial #{} is completed with accuracy: {}\".format(i+1, ensemble_accuracy))\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "print(\"Random Poisoning - {}\".format(per))\n",
    "for classifier_pair in poisoned_accuracies.items():\n",
    "    accuracies = classifier_pair[1]\n",
    "    print(\"{}'s average accuracy: {}\".format(classifier_pair[0], sum(accuracies)/len(accuracies)))\n",
    "print(\"Average ensemble accuracy:\", sum(ensemble_accuracies)/len(ensemble_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac750e0e",
   "metadata": {},
   "source": [
    "## Poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0836fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.ml.classifiers.sklearn.c_classifier_logistic import CClassifierLogistic\n",
    "from secml.adv.attacks.poisoning.c_attack_poisoning_logistic_regression import CAttackPoisoningLogisticRegression\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "\n",
    "lb, ub = 0., 1.  # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "n_poisoning_points = 15  # Number of poisoning points to generate\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.25,\n",
    "    'eta_min': 2.0,\n",
    "    'eta_max': None,\n",
    "    'max_iter': 100,\n",
    "    'eps': 1e-6\n",
    "}\n",
    "\n",
    "dataset = CDataset(X_train, y_train)\n",
    "metric = CMetricAccuracy()\n",
    "\n",
    "# train SVM in the dual space, on a linear kernel, as needed for poisoning\n",
    "c_classifier_LR = CClassifierLogistic()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a757cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Training of c_classifier_LR...\")\n",
    "c_classifier_LR.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = c_classifier_LR.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "pois_attack = CAttackPoisoningLogisticRegression(classifier=c_classifier_LR,\n",
    "                                training_data=dataset,\n",
    "                                val=dataset)\n",
    "pois_attack.n_points = n_poisoning_points\n",
    "\n",
    "# Run the poisoning attack\n",
    "print(\"Attack started...\")\n",
    "pois_y_pred, _, pois_points_ds, _ = pois_attack.run(X_test, y_test)\n",
    "print(\"Attack complete!\")\n",
    "\n",
    "# Evaluate the accuracy of the original classifier\n",
    "acc = metric.performance_score(y_true=y_test, y_pred=c_classifier_LR.predict(X_test))\n",
    "# Evaluate the accuracy after the poisoning attack\n",
    "pois_acc = metric.performance_score(y_true=y_test, y_pred=pois_y_pred)\n",
    "\n",
    "print(\"Original accuracy on test set: {:.2%}\".format(acc))\n",
    "print(\"Accuracy after attack on test set: {:.2%}\".format(pois_acc))\n",
    "\n",
    "print(\"\\n\\n---------------------------\")\n",
    "print(\"END OF LR POISONING\")\n",
    "print(\"---------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312d1c5",
   "metadata": {},
   "source": [
    "## Training with Poisoned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cae829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.ml.classifiers.sklearn.c_classifier_sklearn import CClassifierSkLearn\n",
    "from secml.adv.attacks import CAttackPoisoningSVM\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "\n",
    "lb, ub = 0., 1.  # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "n_poisoning_points = 15  # Number of poisoning points to generate\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.25,\n",
    "    'eta_min': 2.0,\n",
    "    'eta_max': None,\n",
    "    'max_iter': 100,\n",
    "    'eps': 1e-6\n",
    "}\n",
    "\n",
    "classifiers = {\"RFC\": RandomForestClassifier(), \"SVM\": SVC(kernel = 'poly', degree=3), \"SGD\": SGDClassifier(), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "\n",
    "dataset = CDataset(X_train, y_train)\n",
    "\n",
    "metric = CMetricAccuracy()\n",
    "\n",
    "for classifier_pair in classifiers.items():\n",
    "    print(\"---------------------------\")\n",
    "    print(classifier_pair[0])\n",
    "    \n",
    "    classifier = classifier_pair[1]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix', cm)\n",
    "\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "\n",
    "    #compute precision score\n",
    "    precision_score = precision(y_test, y_pred, average='micro')\n",
    "    print('precision', precision_score)\n",
    "\n",
    "    #compute recall score\n",
    "    recall_score = recall(y_test, y_pred)\n",
    "    print('recall', recall_score)\n",
    "\n",
    "    #compute f1 score\n",
    "    f1_score = f1(y_test, y_pred)\n",
    "    print('f1', f1_score)\n",
    "\n",
    "    print(\"---------------------------\")\n",
    "    print(\"POISONING\")\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "    classifier = CClassifierSkLearn(classifier)\n",
    "\n",
    "    pois_attack = CAttackPoisoningSVM(classifier=classifier,\n",
    "                                  training_data=dataset,\n",
    "                                  val=dataset,\n",
    "                                  lb=lb, ub=ub,\n",
    "                                  solver_params=solver_params)\n",
    "    pois_attack.n_points = n_poisoning_points\n",
    "\n",
    "    # Run the poisoning attack\n",
    "    print(\"Attack started...\")\n",
    "    pois_y_pred, _, pois_points_ds, _ = pois_attack.run(X_test, y_test)\n",
    "    print(\"Attack complete!\")\n",
    "\n",
    "    # Evaluate the accuracy of the original classifier\n",
    "    acc = metric.performance_score(y_true=y_test, y_pred=classifier.predict(X_test))\n",
    "    # Evaluate the accuracy after the poisoning attack\n",
    "    pois_acc = metric.performance_score(y_true=y_test, y_pred=pois_y_pred)\n",
    "\n",
    "    print(\"Original accuracy on test set: {:.2%}\".format(acc))\n",
    "    print(\"Accuracy after attack on test set: {:.2%}\".format(pois_acc))\n",
    "\n",
    "    print(\"\\n\\n---------------------------\")\n",
    "    print(\"END OF MODEL\")\n",
    "    print(\"\\n\\n---------------------------\")\n",
    "\n",
    "\n",
    "print(\"---------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
