{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ff535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3870ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 16:18:19.938738: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "#from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import autokeras as ak\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, ReLU\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69a1f9",
   "metadata": {},
   "source": [
    "# Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025a9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "drebin_data_path = 'data/drebin.csv'\n",
    "columns = list(pd.read_csv('data/dataset-features-categories.csv', header = None).iloc[:,0])\n",
    "# Importing the dataset\n",
    "Drebin_data = pd.read_csv(drebin_data_path, names = columns)\n",
    "\n",
    "X = Drebin_data.iloc[:,range(0,Drebin_data.shape[1]-1)].values\n",
    "y = Drebin_data.iloc[:, -1].values\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.astype(int), test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b4d1e",
   "metadata": {},
   "source": [
    "# Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8907912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "SVM\n",
      "accuracy 0.9796054090002216\n",
      "---------------------------\n",
      "MLP\n",
      "accuracy 0.9895810241631567\n",
      "---------------------------\n",
      "XGB\n",
      "accuracy 0.9904677455109732\n",
      "---------------------------\n",
      "LGBM\n",
      "accuracy 0.9904677455109732\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\"SVM\": SVC(kernel = 'linear', degree=3), \"MLP\": MLPClassifier(random_state=1, max_iter=300), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "\n",
    "for classifier_pair in classifiers.items():\n",
    "    print(\"---------------------------\")\n",
    "    print(classifier_pair[0])\n",
    "    classifier = classifier_pair[1]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "    \n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd3355",
   "metadata": {},
   "source": [
    "# AutoKeras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75a5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 215)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 215)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 215)              431       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               55296     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " classification_head_1 (Acti  (None, 1)                0         \n",
      " vation)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,984\n",
      "Trainable params: 63,553\n",
      "Non-trainable params: 431\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "saved_model=keras.models.load_model('structured_data_classifier/best_model', compile=True)\n",
    "print(saved_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781b22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoKerasModel(path_best_model):\n",
    "    saved_model = keras.models.load_model(path_best_model, compile=True)\n",
    "    input_layer = Input(shape=(215,))\n",
    "    x = saved_model.layers[1](input_layer)\n",
    "    x = saved_model.layers[2](x)\n",
    "    x = Dense(units=256)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dense(units=32)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dense(units=1)(x)\n",
    "    x = saved_model.layers[-1](x)\n",
    "    new_model = Model(inputs=input_layer, outputs=x)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555103cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 5s 7ms/step - loss: 0.0952 - accuracy: 0.9662\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0424 - accuracy: 0.9857\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0293 - accuracy: 0.9903\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0162 - accuracy: 0.9953\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0145 - accuracy: 0.9956\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0123 - accuracy: 0.9967\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0112 - accuracy: 0.9969\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0097 - accuracy: 0.9974\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0099 - accuracy: 0.9973\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0100 - accuracy: 0.9976\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0340 - accuracy: 0.9924\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 0.0086 - accuracy: 0.9980\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "141/141 [==============================] - 3s 6ms/step - loss: 0.0786 - accuracy: 0.9909\n",
      "test loss, test acc: [0.07863331586122513, 0.9909111261367798]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 215)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 215)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 215)              431       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               55296     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " classification_head_1 (Acti  (None, 1)                0         \n",
      " vation)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,984\n",
      "Trainable params: 63,553\n",
      "Non-trainable params: 431\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autokeras_model=autoKerasModel('structured_data_classifier/best_model')\n",
    "autokeras_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "autokeras_model.fit(X_train, y_train, epochs=15)\n",
    "results = autokeras_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"test loss, test acc:\", results)\n",
    "print(autokeras_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7946d",
   "metadata": {},
   "source": [
    "# Ensemble Learning - Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c635b5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def majority_voting(y_preds, y_test):\n",
    "    assert y_preds.shape[0] == len(y_test), \"y_preds's length is: {} while y_test's length is: {}. They should be equal.\".format(y_preds.shape[0],len(y_test))\n",
    "    y_pred_vote = []\n",
    "    for preds in y_preds:\n",
    "        if sum(preds) >= 3:\n",
    "            y_pred_vote.append(1)\n",
    "        else:\n",
    "            y_pred_vote.append(0)\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred_vote)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d69997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 3s 10ms/step\n",
      "accuracy 0.9906894258479273\n"
     ]
    }
   ],
   "source": [
    "y_preds = np.ndarray(shape=(5,len(y_test)))\n",
    "i=0\n",
    "for classifier_pair in classifiers.items():\n",
    "    classifier = classifier_pair[1]\n",
    "    y_preds[i] = classifier.predict(X_test)\n",
    "    i += 1\n",
    "y_preds[i] = np.transpose(autokeras_model.predict(X_test, verbose=0))\n",
    "y_preds = np.transpose(y_preds)\n",
    "print('accuracy', majority_voting(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac6377",
   "metadata": {},
   "source": [
    "# Label Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d765dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_label_flipping(X_train, X_test, y_train, y_test, per, classifier, ak=False):\n",
    "    flip_count = int(per*(len(y_train)))\n",
    "    flipped_data = copy.deepcopy(y_train)\n",
    "    indices = random.sample(range(len(flipped_data)), flip_count)\n",
    "    for j in indices:\n",
    "        flipped_data[j] = (flipped_data[j] + 1)%2\n",
    "    if ak:\n",
    "        classifier.fit(X_train, flipped_data, verbose=0, epochs=15)\n",
    "        y_pred = np.transpose(classifier.predict(X_test, verbose=0))\n",
    "    else:\n",
    "        classifier.fit(X_train, flipped_data)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddbcce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Trial #1 is starting...\n",
      "Trial #1 is completed with accuracy: 0.9731766792285524\n",
      "---------------------------\n",
      "Trial #2 is starting...\n",
      "Trial #2 is completed with accuracy: 0.9731766792285524\n",
      "---------------------------\n",
      "Trial #3 is starting...\n",
      "Trial #3 is completed with accuracy: 0.9767235646198182\n",
      "---------------------------\n",
      "Trial #4 is starting...\n",
      "Trial #4 is completed with accuracy: 0.9740634005763689\n",
      "---------------------------\n",
      "Trial #5 is starting...\n",
      "Trial #5 is completed with accuracy: 0.9720682775437819\n",
      "---------------------------\n",
      "Average accuracy is 0.9738417202394147\n"
     ]
    }
   ],
   "source": [
    "percentages = [0.05, 0.1, 0.2, 0.4]\n",
    "\n",
    "accuracies = []\n",
    "print(\"---------------------------\")\n",
    "for i in range(5):\n",
    "    print(\"Trial #{} is starting...\".format(i+1))\n",
    "    poisoned_classifiers = [SVC(kernel = 'linear', degree=3), MLPClassifier(random_state=1, max_iter=300), XGBClassifier(), LGBMClassifier()] \n",
    "    poisoned_autokeras_model=autoKerasModel('structured_data_classifier/best_model')\n",
    "    poisoned_autokeras_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    poisoned_classifiers.append(poisoned_autokeras_model)\n",
    "    y_preds = np.ndarray(shape=(len(poisoned_classifiers),len(y_test)))\n",
    "    ak = False\n",
    "    for j in range(len(poisoned_classifiers)):\n",
    "        if j == len(poisoned_classifiers) - 1:\n",
    "            ak = True\n",
    "        y_preds[j] = attack_label_flipping(X_train, X_test, y_train, y_test, percentages[2], poisoned_classifiers[j], ak)\n",
    "    y_preds = np.transpose(y_preds)\n",
    "    accuracy = majority_voting(y_preds, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print(\"Trial #{} is completed with accuracy: {}\".format(i+1, accuracy))\n",
    "    print(\"---------------------------\")\n",
    "print(\"Average accuracy is\", sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de53925",
   "metadata": {},
   "source": [
    "## SECML Poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c61ab9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.ml.classifiers.sklearn.c_classifier_logistic import CClassifierLogistic\n",
    "from secml.adv.attacks.poisoning.c_attack_poisoning_logistic_regression import CAttackPoisoningLogisticRegression\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "\n",
    "lb, ub = 0., 1.  # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.25,\n",
    "    'eta_min': 2.0,\n",
    "    'eta_max': None,\n",
    "    'max_iter': 100,\n",
    "    'eps': 1e-6\n",
    "}\n",
    "\n",
    "dataset = CDataset(X_train, y_train)\n",
    "metric = CMetricAccuracy()\n",
    "\n",
    "# train SVM in the dual space, on a linear kernel, as needed for poisoning\n",
    "c_classifier_LR = CClassifierLogistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00301be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of c_classifier_LR...\n",
      "CArray([0 0 0 ... 1 0 0])\n",
      "Accuracy on test set: 97.98%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training of c_classifier_LR...\")\n",
    "c_classifier_LR.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = c_classifier_LR.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "acc = metric.performance_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy on test set: {:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c52924",
   "metadata": {},
   "source": [
    "### 10% Poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9be3011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack started...\n",
      "Attack complete!\n",
      "Original accuracy on test set: 97.98%\n",
      "Accuracy after attack on test set: 96.30%\n",
      "\n",
      "---------------------------\n",
      "END OF LR POISONING with 10%\n",
      "---------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poisoning_strength = 0.1 # Percentage of points to poison in training data\n",
    "n_poisoning_points = int(X_train.shape[0] * poisoning_strength)  # Number of poisoning points to generate\n",
    "\n",
    "pois_attack = CAttackPoisoningLogisticRegression(classifier=c_classifier_LR,\n",
    "                                training_data=dataset,\n",
    "                                val=dataset,\n",
    "                                lb=lb, \n",
    "                                ub=ub,\n",
    "                                solver_params=solver_params)\n",
    "pois_attack.n_points = n_poisoning_points\n",
    "\n",
    "# Run the poisoning attack\n",
    "print(\"Attack started...\")\n",
    "pois_y_pred, _, pois_points_ds, _ = pois_attack.run(X_test, y_test)\n",
    "print(\"Attack complete!\")\n",
    "\n",
    "# Evaluate the accuracy of the original classifier\n",
    "acc = metric.performance_score(y_true=y_test, y_pred=c_classifier_LR.predict(X_test))\n",
    "# Evaluate the accuracy after the poisoning attack\n",
    "pois_acc = metric.performance_score(y_true=y_test, y_pred=pois_y_pred)\n",
    "\n",
    "print(\"Original accuracy on test set: {:.2%}\".format(acc))\n",
    "print(\"Accuracy after attack on test set: {:.2z%}\".format(pois_acc))\n",
    "\n",
    "print(\"\\n---------------------------\")\n",
    "print(\"END OF LR POISONING with 10%\")\n",
    "print(\"---------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1ae56",
   "metadata": {},
   "source": [
    "# 20% Poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoning_strength = 0.2 # Percentage of points to poison in training data\n",
    "n_poisoning_points = int(X_train.shape[0] * poisoning_strength)  # Number of poisoning points to generate\n",
    "\n",
    "pois_attack = CAttackPoisoningLogisticRegression(classifier=c_classifier_LR,\n",
    "                                training_data=dataset,\n",
    "                                val=dataset,\n",
    "                                lb=lb, \n",
    "                                ub=ub,\n",
    "                                solver_params=solver_params)\n",
    "pois_attack.n_points = n_poisoning_points\n",
    "\n",
    "# Run the poisoning attack\n",
    "print(\"Attack started...\")\n",
    "pois_y_pred, _, pois_points_ds, _ = pois_attack.run(X_test, y_test)\n",
    "print(\"Attack complete!\")\n",
    "\n",
    "# Evaluate the accuracy of the original classifier\n",
    "acc = metric.performance_score(y_true=y_test, y_pred=c_classifier_LR.predict(X_test))\n",
    "# Evaluate the accuracy after the poisoning attack\n",
    "pois_acc = metric.performance_score(y_true=y_test, y_pred=pois_y_pred)\n",
    "\n",
    "print(\"Original accuracy on test set: {:.2%}\".format(acc))\n",
    "print(\"Accuracy after attack on test set: {:.2%}\".format(pois_acc))\n",
    "\n",
    "print(\"\\n---------------------------\")\n",
    "print(\"END OF LR POISONING with 20%\")\n",
    "print(\"---------------------------\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
