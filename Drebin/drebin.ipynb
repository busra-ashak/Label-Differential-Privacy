{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ff535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3870ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "#from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import autokeras as ak\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, ReLU, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69a1f9",
   "metadata": {},
   "source": [
    "# Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025a9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "drebin_data_path = 'data/drebin.csv'\n",
    "columns = list(pd.read_csv('data/dataset-features-categories.csv', header = None).iloc[:,0])\n",
    "# Importing the dataset\n",
    "Drebin_data = pd.read_csv(drebin_data_path, names = columns)\n",
    "\n",
    "X = Drebin_data.iloc[:,range(0,Drebin_data.shape[1]-1)].values\n",
    "y = Drebin_data.iloc[:, -1].values\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.astype(int), test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b4d1e",
   "metadata": {},
   "source": [
    "# Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8907912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "SVM\n",
      "accuracy 0.9796054090002216\n",
      "---------------------------\n",
      "MLP\n",
      "accuracy 0.9895810241631567\n",
      "---------------------------\n",
      "XGB\n",
      "accuracy 0.9904677455109732\n",
      "---------------------------\n",
      "LGBM\n",
      "accuracy 0.9904677455109732\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\"SVM\": SVC(kernel = 'linear', degree=3), \"MLP\": MLPClassifier(random_state=1, max_iter=300), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "\n",
    "for classifier_pair in classifiers.items():\n",
    "    print(\"---------------------------\")\n",
    "    print(classifier_pair[0])\n",
    "    classifier = classifier_pair[1]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "    \n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd3355",
   "metadata": {},
   "source": [
    "# AutoKeras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75a5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 58s]\n",
      "val_accuracy: 0.9870004653930664\n",
      "\n",
      "Best val_accuracy So Far: 0.9879634380340576\n",
      "Total elapsed time: 00h 23m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/15\n",
      "329/329 [==============================] - 6s 6ms/step - loss: 0.1349 - accuracy: 0.9472\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0566 - accuracy: 0.9810\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0399 - accuracy: 0.9864\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0302 - accuracy: 0.9900\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9923\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0182 - accuracy: 0.9949\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0130 - accuracy: 0.9964\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0112 - accuracy: 0.9973\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0189 - accuracy: 0.9964\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0237 - accuracy: 0.9932\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0118 - accuracy: 0.9965\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.0070 - accuracy: 0.9986\n",
      "INFO:tensorflow:Assets written to: .\\structured_data_classifier\\best_model\\assets\n",
      "141/141 [==============================] - 3s 6ms/step - loss: 0.1070 - accuracy: 0.9874\n",
      "[0.10704107582569122, 0.9873642325401306]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 215)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 215)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 215)              431       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                6912      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               16896     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " classification_head_1 (Acti  (None, 1)                0         \n",
      " vation)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,752\n",
      "Trainable params: 24,321\n",
      "Non-trainable params: 431\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"saved_model=keras.models.load_model('structured_data_classifier/best_model', compile=False)\n",
    "print(saved_model.summary())\"\"\"\n",
    "\n",
    "# Initialize the structured data classifier.\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True, max_trials=10\n",
    ")  # It tries 3 different models.\n",
    "# Feed the structured data classifier with training data.\n",
    "clf.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=15,\n",
    ")\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x=X_test, y=y_test))\n",
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781b22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoKerasModel(path_best_model):\n",
    "    saved_model = keras.models.load_model(path_best_model, compile=True)\n",
    "    input_layer = Input(shape=(215,))\n",
    "    \"\"\"x = saved_model.layers[1](input_layer)\n",
    "    x = saved_model.layers[2](x)\n",
    "    x = Dense(units=256)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dense(units=32)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dense(units=1)(x)\n",
    "    x = saved_model.layers[-1](x)\"\"\"\n",
    "    x = saved_model.layers[1](input_layer)\n",
    "    x = saved_model.layers[2](x)\n",
    "    x = Dense(units=32)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dense(units=512)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = saved_model.layers[-3](x)\n",
    "    x = Dense(units=1)(x)\n",
    "    x = saved_model.layers[-1](x)\n",
    "    new_model = Model(inputs=input_layer, outputs=x)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "555103cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 6s 8ms/step - loss: 0.1320 - accuracy: 0.9487\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 3s 9ms/step - loss: 0.0545 - accuracy: 0.9814\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0406 - accuracy: 0.9864\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0307 - accuracy: 0.9904\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0192 - accuracy: 0.9947\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0174 - accuracy: 0.9944\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0147 - accuracy: 0.9955\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2s 8ms/step - loss: 0.0151 - accuracy: 0.9949\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2s 8ms/step - loss: 0.0295 - accuracy: 0.9927\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0188 - accuracy: 0.9943\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0104 - accuracy: 0.9971\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0083 - accuracy: 0.9981\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0081 - accuracy: 0.9982\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0077 - accuracy: 0.9983\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 0.1134 - accuracy: 0.9880\n",
      "test loss, test acc: [0.1133585050702095, 0.9880292415618896]\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 215)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 215)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 215)              431       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                6912      \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               16896     \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " classification_head_1 (Acti  (None, 1)                0         \n",
      " vation)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,752\n",
      "Trainable params: 24,321\n",
      "Non-trainable params: 431\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autokeras_model=autoKerasModel('structured_data_classifier/best_model')\n",
    "autokeras_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "autokeras_model.fit(X_train, y_train, epochs=15)\n",
    "results = autokeras_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"test loss, test acc:\", results)\n",
    "print(autokeras_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7946d",
   "metadata": {},
   "source": [
    "# Ensemble Learning - Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c635b5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def majority_voting(y_preds, y_test):\n",
    "    assert y_preds.shape[0] == len(y_test), \"y_preds's length is: {} while y_test's length is: {}. They should be equal.\".format(y_preds.shape[0],len(y_test))\n",
    "    y_pred_vote = []\n",
    "    for preds in y_preds:\n",
    "        if sum(preds) >= 3:\n",
    "            y_pred_vote.append(1)\n",
    "        else:\n",
    "            y_pred_vote.append(0)\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred_vote)\n",
    "    return accuracy, y_pred_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d69997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9906894258479273\n"
     ]
    }
   ],
   "source": [
    "y_preds = np.ndarray(shape=(5,len(y_test)))\n",
    "i=0\n",
    "for classifier_pair in classifiers.items():\n",
    "    classifier = classifier_pair[1]\n",
    "    y_preds[i] = classifier.predict(X_test)\n",
    "    i += 1\n",
    "y_preds[i] = np.transpose(autokeras_model.predict(X_test, verbose=0))\n",
    "y_preds = np.transpose(y_preds)\n",
    "accuracy, _ = majority_voting(y_preds, y_test)\n",
    "print('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac6377",
   "metadata": {},
   "source": [
    "# Label Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d765dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_label_flipping(X_train, X_test, flipped_data, y_test, per, classifier_name, classifier):\n",
    "    accuracy = 0\n",
    "    if classifier_name == \"AutoKeras\":\n",
    "        classifier.fit(X_train, flipped_data, verbose=0, epochs=15)\n",
    "        y_pred = np.transpose(classifier.predict(X_test, verbose=0))\n",
    "        accuracy = classifier.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    else:\n",
    "        classifier.fit(X_train, flipped_data)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        accuracy = acc(y_test, y_pred)\n",
    "    return y_pred, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbc4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flipping Random\n",
    "def random_label_flipping(y_train, per):\n",
    "    flip_count = int(per*(len(y_train)))\n",
    "    flipped_data = copy.deepcopy(y_train)\n",
    "    indices = random.sample(range(len(flipped_data)), flip_count)\n",
    "    for j in indices:\n",
    "        flipped_data[j] = (flipped_data[j] + 1)%2\n",
    "    return flipped_data\n",
    "\n",
    "#Flipping Specific\n",
    "def specific_label_flipping(y_train, per, target):\n",
    "    flipped_data = copy.deepcopy(y_train)\n",
    "    possible_indices = []\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] == target:\n",
    "            possible_indices.append(i)\n",
    "    flip_count = int(per*(len(possible_indices)))\n",
    "    indices = random.sample(possible_indices, flip_count)\n",
    "    for j in indices:\n",
    "        flipped_data[j] = (flipped_data[j] + 1)%2\n",
    "    return flipped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ddbcce5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Trial #1 is starting...\n",
      "Trial #1 is completed with accuracy: 0.97251163821769\n",
      "---------------------------\n",
      "Trial #2 is starting...\n",
      "Trial #2 is completed with accuracy: 0.97628020394591\n",
      "---------------------------\n",
      "Trial #3 is starting...\n",
      "Trial #3 is completed with accuracy: 0.9711815561959655\n",
      "---------------------------\n",
      "Trial #4 is starting...\n",
      "Trial #4 is completed with accuracy: 0.9729549988915983\n",
      "---------------------------\n",
      "Trial #5 is starting...\n",
      "Trial #5 is completed with accuracy: 0.9771669252937264\n",
      "---------------------------\n",
      "Random Poisoning - 0.2\n",
      "SVM's average accuracy: 0.9626246951895366\n",
      "MLP's average accuracy: 0.9632454001330082\n",
      "XGB's average accuracy: 0.9724673021502992\n",
      "LGBM's average accuracy: 0.976989581024163\n",
      "AutoKeras's average accuracy: 0.9781866669654846\n",
      "Average ensemble accuracy: 0.9740190645089781\n"
     ]
    }
   ],
   "source": [
    "percentages = [0.01, 0.05, 0.1, 0.2]\n",
    "per = percentages[3]\n",
    "poisoned_accuracies = {\"SVM\": [], \"MLP\": [], \"XGB\": [], \"LGBM\": [], \"AutoKeras\": []}\n",
    "ensemble_accuracies = []\n",
    "\n",
    "print(\"---------------------------\")\n",
    "for i in range(5):\n",
    "    print(\"Trial #{} is starting...\".format(i+1))\n",
    "    \n",
    "    poisoned_classifiers = {\"SVM\": SVC(kernel = 'linear', degree=3), \"MLP\": MLPClassifier(random_state=1, max_iter=300), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "    poisoned_autokeras_model=autoKerasModel('structured_data_classifier/best_model')\n",
    "    poisoned_autokeras_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    poisoned_classifiers[\"AutoKeras\"] = poisoned_autokeras_model\n",
    "    \n",
    "    flipped_data = random_label_flipping(y_train, per)\n",
    "    y_preds = np.ndarray(shape=(len(poisoned_classifiers),len(y_test)))\n",
    "    j=0\n",
    "    for classifier_pair in poisoned_classifiers.items():\n",
    "        poisoned_y_pred, poisoned_accuracy = attack_label_flipping(X_train, X_test, flipped_data, y_test, per, classifier_pair[0], classifier_pair[1])\n",
    "        y_preds[j] = poisoned_y_pred\n",
    "        j+=1\n",
    "        poisoned_accuracies[classifier_pair[0]].append(poisoned_accuracy)\n",
    "    y_preds = np.transpose(y_preds)\n",
    "    \n",
    "    ensemble_accuracy, _ = majority_voting(y_preds, y_test)\n",
    "    ensemble_accuracies.append(ensemble_accuracy)\n",
    "    \n",
    "    print(\"Trial #{} is completed with accuracy: {}\".format(i+1, ensemble_accuracy))\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "print(\"Random Poisoning - {}\".format(per))\n",
    "for classifier_pair in poisoned_accuracies.items():\n",
    "    accuracies = classifier_pair[1]\n",
    "    print(\"{}'s average accuracy: {}\".format(classifier_pair[0], sum(accuracies)/len(accuracies)))\n",
    "print(\"Average ensemble accuracy:\", sum(ensemble_accuracies)/len(ensemble_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee641502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVM': [0.9796054090002216], 'MLP': [0.9895810241631567], 'XGB': [0.9904677455109732], 'LGBM': [0.9904677455109732], 'AutoKeras': [0.9842606782913208]}\n",
      "Trial is completed with accuracy: 0.9909111061848814\n",
      "---------------------------\n",
      "SVM 0.985938242280285\n",
      "MLP 0.9989548693586698\n",
      "XGB 0.9980997624703087\n",
      "LGBM 0.9964845605700713\n",
      "329/329 [==============================] - 3s 9ms/step - loss: 0.0067 - accuracy: 0.9988\n",
      "AutoKeras 0.9987648725509644\n",
      "ensemble 0.9970546318289786\n"
     ]
    }
   ],
   "source": [
    "percentages = [0.01, 0.05, 0.1, 0.2]\n",
    "per = percentages[3]\n",
    "poisoned_accuracies = {\"SVM\": [], \"MLP\": [], \"XGB\": [], \"LGBM\": [], \"AutoKeras\": []}\n",
    "\n",
    "poisoned_classifiers = {\"SVM\": SVC(kernel = 'linear', degree=3), \"MLP\": MLPClassifier(random_state=1, max_iter=300), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "poisoned_autokeras_model=autoKerasModel('structured_data_classifier/best_model')\n",
    "poisoned_autokeras_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "poisoned_classifiers[\"AutoKeras\"] = poisoned_autokeras_model\n",
    "\n",
    "flipped_data = random_label_flipping(y_train, per)\n",
    "y_preds = np.ndarray(shape=(len(poisoned_classifiers),len(y_test)))\n",
    "j=0\n",
    "\n",
    "for classifier_pair in poisoned_classifiers.items():\n",
    "    poisoned_y_pred, poisoned_accuracy = attack_label_flipping(X_train, X_test, y_train, y_test, per, classifier_pair[0], classifier_pair[1])\n",
    "    y_preds[j] = poisoned_y_pred\n",
    "    j+=1\n",
    "    poisoned_accuracies[classifier_pair[0]].append(poisoned_accuracy)\n",
    "y_preds = np.transpose(y_preds)\n",
    "print(poisoned_accuracies)\n",
    "ensemble_accuracy, y_pred_vote = majority_voting(y_preds, y_test)\n",
    "\n",
    "print(\"Trial is completed with accuracy: {}\".format(ensemble_accuracy))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "y_preds_train = np.ndarray(shape=(len(poisoned_classifiers),len(y_train)))\n",
    "z=0\n",
    "for classifier_pair in poisoned_classifiers.items():\n",
    "    y_pred = []\n",
    "    if classifier_pair[0] == \"AutoKeras\":\n",
    "        y_pred = np.transpose(classifier_pair[1].predict(X_train, verbose=0))\n",
    "        accuracy = classifier_pair[1].evaluate(X_train, y_train)[1]\n",
    "    else:\n",
    "        y_pred = classifier_pair[1].predict(X_train)\n",
    "        accuracy = acc(y_train, y_pred)\n",
    "    y_preds_train[z] = y_pred\n",
    "    z+=1\n",
    "    print(classifier_pair[0], accuracy)\n",
    "\n",
    "y_preds_train = np.transpose(y_preds_train)\n",
    "train_acc, y_pred_train_vote = majority_voting(y_preds_train, y_train)\n",
    "print(\"ensemble\", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c0db8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "SVM 0.011306413301662708\n",
      "MLP 0.0019002375296912114\n",
      "XGB 0.0010451306413301663\n",
      "LGBM 0.0009501187648456057\n",
      "AutoKeras 0.7222802850356295\n"
     ]
    }
   ],
   "source": [
    "t=0\n",
    "defo_poison = 0\n",
    "for a in range(len(y_train)):\n",
    "    if y_train[a] != flipped_data[a]:\n",
    "        defo_poison +=1\n",
    "print(defo_poison/len(y_train))\n",
    "for classifier_pair in poisoned_classifiers.items():\n",
    "    poison_maybe = 0\n",
    "    for k in range(len(y_pred_train_vote)):\n",
    "        if y_pred_train_vote[k] != y_preds_train[k][t]:\n",
    "            poison_maybe += 1\n",
    "    t+=1\n",
    "    print(classifier_pair[0], poison_maybe/len(y_pred_train_vote))\n",
    "    \n",
    "#her seferinde data farklı olucak average prediction ı da alamam?\n",
    "#ya da bu outputların ortalamasını alıcam ama çok farketmez sanki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de53925",
   "metadata": {},
   "source": [
    "# SECML Poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61ab9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of c_classifier_LR...\n",
      "Training of c_classifier_LR is done!\n"
     ]
    }
   ],
   "source": [
    "from secml.ml.classifiers.sklearn.c_classifier_logistic import CClassifierLogistic\n",
    "from secml.adv.attacks.poisoning.c_attack_poisoning_logistic_regression import CAttackPoisoningLogisticRegression\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "\n",
    "lob, ub = 0., 1.  # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.25,\n",
    "    'eta_min': 2.0,\n",
    "    'eta_max': None,\n",
    "    'max_iter': 100,\n",
    "    'eps': 1e-6\n",
    "}\n",
    "\n",
    "dataset = CDataset(X_train, y_train)\n",
    "metric = CMetricAccuracy()\n",
    "\n",
    "# train SVM in the dual space, on a linear kernel, as needed for poisoning\n",
    "c_classifier_LR = CClassifierLogistic()\n",
    "print(\"Training of c_classifier_LR...\")\n",
    "c_classifier_LR.fit(X_train, y_train)\n",
    "print(\"Training of c_classifier_LR is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9be3011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack started...\n",
      "Attack complete!\n"
     ]
    }
   ],
   "source": [
    "poisoning_strength = 0.1 # Percentage of points to poison in training data\n",
    "n_poisoning_points = 2  # Number of poisoning points to generate\n",
    "\n",
    "pois_attack = CAttackPoisoningLogisticRegression(classifier=c_classifier_LR,\n",
    "                                training_data=dataset,\n",
    "                                val=dataset,\n",
    "                                lb=lob, \n",
    "                                ub=ub,\n",
    "                                solver_params=solver_params)\n",
    "pois_attack.n_points = n_poisoning_points\n",
    "\n",
    "# Run the poisoning attack\n",
    "print(\"Attack started...\")\n",
    "pois_y_pred, _, pois_points_ds, _ = pois_attack.run(X_test, y_test)\n",
    "print(\"Attack complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f4938",
   "metadata": {},
   "source": [
    "# Reading Poisoned data & adding to/replacing with training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27d40aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "pois_points_path = 'poisoning-20.csv'\n",
    "# Importing the dataset\n",
    "pois_points_ds = pd.read_csv(pois_points_path)\n",
    "pois_points_X = pois_points_ds.iloc[:,range(0,pois_points_ds.shape[1]-1)].values\n",
    "pois_points_y = pois_points_ds.iloc[:, -1].values\n",
    "\n",
    "pois_points_y = lb.fit_transform(pois_points_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b8fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Trial #1 is starting...\n",
      "Trial #1 is completed with accuracy: 0.9893593438262026\n",
      "---------------------------\n",
      "SECML Poisoning - 10%\n",
      "SVM's average accuracy: 0.9687430724894702\n",
      "MLP's average accuracy: 0.9824872533806251\n",
      "XGB's average accuracy: 0.9886943028153403\n",
      "LGBM's average accuracy: 0.9895810241631567\n",
      "AutoKeras's average accuracy: 0.9895810484886169\n",
      "Average ensemble accuracy: 0.9893593438262026\n"
     ]
    }
   ],
   "source": [
    "poisoned_accuracies = {\"SVM\": [], \"MLP\": [], \"XGB\": [], \"LGBM\": [], \"AutoKeras\": []}\n",
    "ensemble_accuracies = []\n",
    "print(\"---------------------------\")\n",
    "for trial in range(5):\n",
    "    pois_X_train = copy.deepcopy(X_train)\n",
    "    pois_y_train = copy.deepcopy(y_train)\n",
    "\n",
    "    #Uncomment below to RANDOMLY REPLACE with poisoned data\n",
    "    to_be_replaced = random.sample(range(len(pois_X_train)), len(pois_points_X))\n",
    "    new_data = 0\n",
    "    for index in to_be_replaced:\n",
    "        pois_X_train[index] = pois_points_X[new_data]\n",
    "        pois_y_train[index] = pois_points_y[new_data]\n",
    "        new_data += 1\n",
    "\n",
    "    #Uncomment below to ADD poisoned data\n",
    "    \"\"\"pois_X_train = np.append(pois_X_train, pois_points_X, axis=0)\n",
    "    pois_y_train = np.append(pois_y_train, pois_points_y)\"\"\"\n",
    "\n",
    "    print(\"Trial #{} is starting...\".format(trial+1))\n",
    "    \n",
    "    classifiers_secml = {\"SVM\": SVC(kernel = 'linear', degree=3), \"MLP\": MLPClassifier(random_state=1, max_iter=300), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "    \n",
    "    y_preds = np.ndarray(shape=(5,len(y_test)))\n",
    "    j=0\n",
    "    for classifier_pair in classifiers_secml.items():\n",
    "        classifier = classifier_pair[1]\n",
    "        classifier.fit(pois_X_train, pois_y_train)\n",
    "        # Predicting the Test set results\n",
    "        poisoned_y_pred = classifier.predict(X_test)\n",
    "        y_preds[j] = poisoned_y_pred\n",
    "        #compute accuracy_score\n",
    "        poisoned_accuracy = acc(y_test, poisoned_y_pred)\n",
    "        poisoned_accuracies[classifier_pair[0]].append(poisoned_accuracy)\n",
    "        j+=1\n",
    "        \n",
    "    ak_model_secml=autoKerasModel('structured_data_classifier/best_model')\n",
    "    ak_model_secml.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    ak_model_secml.fit(pois_X_train, pois_y_train, epochs=15, verbose=0)\n",
    "    y_preds[j] = np.transpose(ak_model_secml.predict(X_test, verbose=0))\n",
    "    poisoned_accuracies[\"AutoKeras\"].append(ak_model_secml.evaluate(X_test, y_test, verbose=0)[1])\n",
    "\n",
    "    y_preds = np.transpose(y_preds)\n",
    "    \n",
    "    ensemble_accuracy = majority_voting(y_preds, y_test)\n",
    "    ensemble_accuracies.append(ensemble_accuracy)\n",
    "    \n",
    "    print(\"Trial #{} is completed with accuracy: {}\".format(trial+1, ensemble_accuracy))\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "print(\"SECML Poisoning - 20%\")\n",
    "for classifier_pair in poisoned_accuracies.items():\n",
    "    accuracies = classifier_pair[1]\n",
    "    print(\"{}'s average accuracy: {}\".format(classifier_pair[0], sum(accuracies)/len(accuracies)))\n",
    "print(\"Average ensemble accuracy:\", sum(ensemble_accuracies)/len(ensemble_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42379ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
