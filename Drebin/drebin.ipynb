{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ff535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3870ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "#from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import autokeras as ak\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, ReLU, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025a9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "drebin_data_path = 'data\\drebin.csv'\n",
    "columns = list(pd.read_csv('data\\dataset-features-categories.csv', header = None).iloc[:,0])\n",
    "# Importing the dataset\n",
    "Drebin_data = pd.read_csv(drebin_data_path, names = columns)\n",
    "\n",
    "X = Drebin_data.iloc[:,range(0,Drebin_data.shape[1]-1)].values\n",
    "y = Drebin_data.iloc[:, -1].values\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.astype(int), test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b4d1e",
   "metadata": {},
   "source": [
    "# Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8907912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "SVM\n",
      "Confusion Matrix [[2851   47]\n",
      " [  45 1568]]\n",
      "accuracy 0.9796054090002216\n",
      "precision 0.9796054090002216\n",
      "recall 0.972101673899566\n",
      "f1 0.9714993804213135\n",
      "---------------------------\n",
      "MLP\n",
      "Confusion Matrix [[2880   18]\n",
      " [  29 1584]]\n",
      "accuracy 0.9895810241631567\n",
      "precision 0.9895810241631567\n",
      "recall 0.9820210787352759\n",
      "f1 0.9853810264385693\n",
      "---------------------------\n",
      "XGB\n",
      "Confusion Matrix [[2882   16]\n",
      " [  27 1586]]\n",
      "accuracy 0.9904677455109732\n",
      "precision 0.9904677455109732\n",
      "recall 0.9832610043397396\n",
      "f1 0.9866251944012442\n",
      "---------------------------\n",
      "LGBM\n",
      "Confusion Matrix [[2884   14]\n",
      " [  29 1584]]\n",
      "accuracy 0.9904677455109732\n",
      "precision 0.9904677455109732\n",
      "recall 0.9820210787352759\n",
      "f1 0.9866085331672375\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\"SVM\": SVC(kernel = 'linear', degree=3), \"MLP\": MLPClassifier(random_state=1, max_iter=300), \"XGB\": XGBClassifier(), \"LGBM\": LGBMClassifier()} \n",
    "\n",
    "for classifier_pair in classifiers.items():\n",
    "    print(\"---------------------------\")\n",
    "    print(classifier_pair[0])\n",
    "    \n",
    "    classifier = classifier_pair[1]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix', cm)\n",
    "\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "\n",
    "    #compute precision score\n",
    "    precision_score = precision(y_test, y_pred, average='micro')\n",
    "    print('precision', precision_score)\n",
    "\n",
    "    #compute recall score\n",
    "    recall_score = recall(y_test, y_pred)\n",
    "    print('recall', recall_score)\n",
    "\n",
    "    #compute f1 score\n",
    "    f1_score = f1(y_test, y_pred)\n",
    "    print('f1', f1_score)\n",
    "    \n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd3355",
   "metadata": {},
   "source": [
    "# AutoKeras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75a5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 215)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 215)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 215)              431       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               55296     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " classification_head_1 (Acti  (None, 1)                0         \n",
      " vation)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,984\n",
      "Trainable params: 63,553\n",
      "Non-trainable params: 431\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "saved_model=keras.models.load_model('structured_data_classifier\\best_model', compile=True)\n",
    "print(saved_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781b22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoKerasModel(path_best_model):\n",
    "    saved_model = keras.models.load_model(path_best_model, compile=True)\n",
    "    input_layer = Input(shape=(215,))\n",
    "    x = saved_model.layers[1](input_layer)\n",
    "    x = saved_model.layers[2](x)\n",
    "    x = Dense(units=256)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dense(units=32)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dense(units=1)(x)\n",
    "    x = saved_model.layers[-1](x)\n",
    "    new_model = Model(inputs=input_layer, outputs=x)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555103cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 5s 6ms/step - loss: 0.0988 - accuracy: 0.9645\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0416 - accuracy: 0.9864\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9910\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0195 - accuracy: 0.9938\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0160 - accuracy: 0.9951\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0132 - accuracy: 0.9957\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9933\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0125 - accuracy: 0.9970\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0090 - accuracy: 0.9981\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0080 - accuracy: 0.9978\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 4s 11ms/step - loss: 0.0094 - accuracy: 0.9974\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 3s 9ms/step - loss: 0.0080 - accuracy: 0.9986\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 3s 8ms/step - loss: 0.0071 - accuracy: 0.9984\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0198 - accuracy: 0.9955\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 0.0134 - accuracy: 0.9966\n",
      "141/141 [==============================] - 4s 7ms/step - loss: 0.0826 - accuracy: 0.9885\n",
      "test loss, test acc: [0.08261679857969284, 0.9884726405143738]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 215)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 215)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 215)              431       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               55296     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " classification_head_1 (Acti  (None, 1)                0         \n",
      " vation)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,984\n",
      "Trainable params: 63,553\n",
      "Non-trainable params: 431\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autokeras_model=autoKerasModel('structured_data_classifier/best_model')\n",
    "autokeras_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "autokeras_model.fit(X_train, y_train, epochs=15)\n",
    "results = autokeras_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"test loss, test acc:\", results)\n",
    "print(autokeras_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7946d",
   "metadata": {},
   "source": [
    "# Ensemble Learning - Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c635b5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def majority_voting(classifiers, autokeras_model):\n",
    "    y_preds = np.ndarray(shape=(5,len(y_test)))\n",
    "    i=0\n",
    "    for classifier_pair in classifiers.items():\n",
    "        classifier = classifier_pair[1]\n",
    "        # Predicting the Test set results\n",
    "        y_preds[i] = classifier.predict(X_test)\n",
    "        i += 1\n",
    "    y_preds[i] = np.transpose(autokeras_model.predict(X_test))\n",
    "    y_preds = np.transpose(y_preds)\n",
    "    y_pred = []\n",
    "    for preds in y_preds:\n",
    "        if sum(preds) >= 3:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d69997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 3s 7ms/step\n",
      "accuracy 0.9906894258479273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9906894258479273"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_voting(classifiers, autokeras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d765dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_privacy",
   "language": "python",
   "name": "data_privacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
