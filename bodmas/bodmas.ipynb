{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ff535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3870ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 17:25:37.112476: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "#from imutils import paths\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025a9cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134435, 2381) (134435,)\n",
      "(94104, 2381) (40331, 2381)\n"
     ]
    }
   ],
   "source": [
    "filename = 'bodmas.npz'\n",
    "data = np.load('./' + filename)\n",
    "X = data['X']  # all the feature vectors\n",
    "y = data['y']  # labels, 0 as benign, 1 as malicious\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.astype(int), test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b4d1e",
   "metadata": {},
   "source": [
    "# Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8907912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "---------------------------\n",
      "GaussianNB\n",
      "Confusion Matrix [[10293 12751]\n",
      " [  516 16771]]\n",
      "accuracy 0.671047085368575\n",
      "precision 0.671047085368575\n",
      "recall 0.9701509805055822\n",
      "f1 0.7165715994787327\n",
      "---------------------------\n",
      "RFC\n",
      "Confusion Matrix [[23006    38]\n",
      " [  181 17106]]\n",
      "accuracy 0.994569933797823\n",
      "precision 0.994569933797823\n",
      "recall 0.9895297044021519\n",
      "f1 0.9936394528186809\n",
      "---------------------------\n",
      "SVM\n",
      "Confusion Matrix [[22581   463]\n",
      " [  327 16960]]\n",
      "accuracy 0.9804120899556172\n",
      "precision 0.9804120899556172\n",
      "recall 0.9810840515994678\n",
      "f1 0.9772399884759435\n",
      "---------------------------\n",
      "DT\n",
      "Confusion Matrix [[22783   261]\n",
      " [  196 17091]]\n",
      "accuracy 0.9886687659616672\n",
      "precision 0.9886687659616672\n",
      "recall 0.9886620003470816\n",
      "f1 0.9868067784866769\n",
      "---------------------------\n",
      "SGD\n",
      "Confusion Matrix [[22826   218]\n",
      " [  364 16923]]\n",
      "accuracy 0.9855694131065433\n",
      "precision 0.9855694131065433\n",
      "recall 0.9789437149302944\n",
      "f1 0.983095155106309\n",
      "---------------------------\n",
      "MLP\n",
      "Confusion Matrix [[22933   111]\n",
      " [  106 17181]]\n",
      "accuracy 0.994619523443505\n",
      "precision 0.994619523443505\n",
      "recall 0.9938682246775034\n",
      "f1 0.9937245148789727\n",
      "---------------------------\n",
      "XGB\n",
      "Confusion Matrix [[23020    24]\n",
      " [   80 17207]]\n",
      "accuracy 0.997421338424537\n",
      "precision 0.997421338424537\n",
      "recall 0.9953722450396252\n",
      "f1 0.9969870792050525\n",
      "---------------------------\n",
      "LGBM\n",
      "Confusion Matrix [[22993    51]\n",
      " [   88 17199]]\n",
      "accuracy 0.9965535196251023\n",
      "precision 0.9965535196251023\n",
      "recall 0.9949094695435877\n",
      "f1 0.9959753308046443\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5,  n_repeats=3, random_state=999)\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(-10,10, num=2000)}\n",
    "\n",
    "#gs_NB = GridSearchCV(estimator=GaussianNB(), param_grid=params_NB, cv=cv_method,verbose=1,scoring='accuracy')\n",
    "\n",
    "classifiers = {\"GaussianNB\": GaussianNB(), \"RFC\": RandomForestClassifier(), \"SVM\": SVC(kernel = 'poly', degree=3), \n",
    "               \"DT\": DecisionTreeClassifier(), \"SGD\": SGDClassifier(), \n",
    "               \"MLP\": MLPClassifier(random_state=1, max_iter=300), \"XGB\": XGBClassifier(), \n",
    "               \"LGBM\": LGBMClassifier()} \n",
    "\n",
    "print('Starting training...')\n",
    "\n",
    "for classifier_pair in classifiers.items():\n",
    "    print(\"---------------------------\")\n",
    "    print(classifier_pair[0])\n",
    "    \n",
    "    classifier = classifier_pair[1]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix', cm)\n",
    "\n",
    "    #compute accuracy_score\n",
    "    accuracy = acc(y_test, y_pred)\n",
    "    print('accuracy', accuracy)\n",
    "\n",
    "    #compute precision score\n",
    "    precision_score = precision(y_test, y_pred, average='micro')\n",
    "    print('precision', precision_score)\n",
    "\n",
    "    #compute recall score\n",
    "    recall_score = recall(y_test, y_pred)\n",
    "    print('recall', recall_score)\n",
    "\n",
    "    #compute f1 score\n",
    "    f1_score = f1(y_test, y_pred)\n",
    "    print('f1', f1_score)\n",
    "    \n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46fa2268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 17:26:20.109640: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the structured data classifier.\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True, max_trials=10\n",
    ")  # It tries 3 different models.\n",
    "# Feed the structured data classifier with training data.\n",
    "clf.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=15,\n",
    ")\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x=X_test, y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
